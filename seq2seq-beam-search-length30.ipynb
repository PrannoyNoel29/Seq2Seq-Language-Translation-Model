{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import math\n",
    "import operator\n",
    "import random\n",
    "from queue import PriorityQueue\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    x_files = ['IWSLT14.TED.dev2010.en-fr.en.xml','IWSLT14.TED.tst2010.en-fr.en.xml']\n",
    "    y_files = ['IWSLT14.TED.dev2010.en-fr.fr.xml','IWSLT14.TED.tst2010.en-fr.fr.xml']\n",
    "    \n",
    "    x_files = ['IWSLT14.TED.tst2011.en-fr.en.xml', 'IWSLT14.TED.tst2012.en-fr.en.xml']\n",
    "    y_files = ['IWSLT14.TED.tst2011.en-fr.fr.xml', 'IWSLT14.TED.tst2012.en-fr.fr.xml']\n",
    "\n",
    "    eng = []\n",
    "    fr = []\n",
    "\n",
    "    for i,j in zip(x_files, y_files):\n",
    "        tree_eng = ET.parse(i)\n",
    "        root_eng = tree_eng.getroot()\n",
    "\n",
    "        tree_fr = ET.parse(j)\n",
    "        root_fr = tree_fr.getroot()\n",
    "\n",
    "        for k in root_eng.iter('seg'):\n",
    "            eng.append(k.text.strip())\n",
    "\n",
    "        for l in root_fr.iter('seg'):\n",
    "            fr.append(l.text.strip())\n",
    "            \n",
    "    eng_norm = [normalizeString(l) for l in eng]\n",
    "    fr_norm = [normalizeString(l) for l in fr]\n",
    "    \n",
    "    pairs = zip(eng_norm, fr_norm)\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 1942 sentence pairs\n",
      "Trimmed to 51 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 280\n",
      "eng 265\n",
      "['ils s entrainent juste .', 'they re just practicing .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, n_layers = 1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, n_layers)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers = 1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers  # 1\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]])\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = []\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            loss_values.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Beam search for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "#         decoder_input = torch.tensor([[SOS_token]])  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        \n",
    "#         beam_width = 3\n",
    "        beam_width = 50\n",
    "        topk = 1  # how many sentence do you want to generate\n",
    "        decoded_batch = []\n",
    "\n",
    "        # Start with the start of the sentence token\n",
    "        decoder_input = torch.LongTensor([SOS_token])\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = min((topk + 1), topk - len(endnodes))\n",
    "        number_required = 1\n",
    "\n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.len_pen(), node))\n",
    "        qsize = 1\n",
    "\n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: \n",
    "                break\n",
    "#             print(nodes.get())\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            \n",
    "            # print('--best node seqs len {} '.format(n.leng))\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "#             print(decoder_output.shape)\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_width)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_width):\n",
    "                decoded_t = indexes[0][new_k].view(-1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "#                 print('Previous Node : '.format(n))\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.len_pen()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "\n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(topk)]\n",
    "\n",
    "        utterance = []\n",
    "        for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
    "            utterance.append(int(n.wordid))\n",
    "            while n.prevNode != None:\n",
    "                n = n.prevNode\n",
    "                utterance.append(int(n.wordid))\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "#                 utterances.append(utterance)\n",
    "\n",
    "#             decoded_batch.append(utterance)\n",
    "# #             print(decoded_batch)\n",
    "#             decoded_batch = decoded_batch[0][0]\n",
    "        decoded_words = [output_lang.index2word[word] for word in utterance]\n",
    "        return decoded_words, decoder_attentions     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1):\n",
    "        reward =0\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward  # Length Penalty: keeping it to 0\n",
    "    \n",
    "    def len_pen(self, penalty_factor=10):\n",
    "        return tf.math.divide((5. + tf.compat.v1.to_float(self.leng))**penalty_factor, (5. + 1.)**penalty_factor) # Length penalty\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return self.leng < other.leng  \n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return self.leng > other.leng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4m 2s (- 56m 36s) (5000 6%) 0.8223\n",
      "8m 8s (- 52m 54s) (10000 13%) 0.0055\n",
      "12m 13s (- 48m 54s) (15000 20%) 0.0026\n",
      "16m 20s (- 44m 55s) (20000 26%) 0.0017\n",
      "20m 28s (- 40m 56s) (25000 33%) 0.0013\n",
      "24m 34s (- 36m 52s) (30000 40%) 0.0010\n",
      "28m 38s (- 32m 44s) (35000 46%) 0.0008\n",
      "32m 46s (- 28m 40s) (40000 53%) 0.0007\n",
      "36m 47s (- 24m 31s) (45000 60%) 0.0006\n",
      "40m 52s (- 20m 26s) (50000 66%) 0.0005\n",
      "44m 57s (- 16m 20s) (55000 73%) 0.0005\n",
      "48m 55s (- 12m 13s) (60000 80%) 0.0004\n",
      "52m 53s (- 8m 8s) (65000 86%) 0.0004\n",
      "56m 50s (- 4m 3s) (70000 93%) 0.0004\n",
      "60m 48s (- 0m 0s) (75000 100%) 0.0003\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000) \n",
    "# 2, 37,  3, 19, 18, 10, 11, 22, 38, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam width = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> nous sommes tous des specialistes maintenant meme les medecins de premiers secours .\n",
      "= we re all specialists now even the primary care physicians .\n",
      "< SOS we re all specialists now even the primary care physicians . EOS\n",
      "\n",
      "> ils sont aussi assez riches et aises et toutes ces autres sortes de choses .\n",
      "= they re also fairly wealthy and affluent and all these other sorts of things .\n",
      "< SOS they re also fairly wealthy and affluent and all these other sorts of things . EOS\n",
      "\n",
      "> il est un ancien aborigenes australiens et c est aussi un artiste .\n",
      "= he s an australian aboriginal elder and he s also an artist .\n",
      "< SOS he s an australian aboriginal elder and he s also an artist . EOS\n",
      "\n",
      "> il est un ancien aborigenes australiens et c est aussi un artiste .\n",
      "= he s an australian aboriginal elder and he s also an artist .\n",
      "< SOS he s an australian aboriginal elder and he s also an artist . EOS\n",
      "\n",
      "> je vais vous montrer .\n",
      "= i m going to do some demonstrations .\n",
      "< SOS i m going to do some demonstrations . EOS\n",
      "\n",
      "> je suis un savant autiste ou plus exactement un autiste savant avec un fonctionnement eleve .\n",
      "= i m a savant or more precisely a high functioning autistic savant .\n",
      "< SOS i m a savant or more precisely a high functioning autistic savant . EOS\n",
      "\n",
      "> je suis acteur .\n",
      "= i m a performer .\n",
      "< SOS i m a performer . EOS\n",
      "\n",
      "> nous commencons a vendre des voitures electriques et c est genial .\n",
      "= we re starting to sell electric cars which is great .\n",
      "< SOS we re starting to sell electric cars which is great . EOS\n",
      "\n",
      "> ils acceptent plus la tristesse que les gens plus jeunes .\n",
      "= they re more accepting of sadness than younger people are .\n",
      "< SOS they re more accepting of sadness than younger people are . EOS\n",
      "\n",
      "> je vais faire une biennale internationale j ai besoin d artistes du monde entier .\n",
      "= i m going to do an international biennial i need artists from all around the world .\n",
      "< SOS i m going to do an international biennial i need artists from all around the world . EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "def bleuScore(test_y_pred, test_y_actuals): #2 lists\n",
    "    bleu = sacrebleu.corpus_bleu(test_y_pred, [test_y_actuals])\n",
    "    return bleu.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs_test(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    x_files = ['IWSLT14.TED.tst2011.en-fr.en.xml', 'IWSLT14.TED.tst2012.en-fr.en.xml']\n",
    "    y_files = ['IWSLT14.TED.tst2011.en-fr.fr.xml', 'IWSLT14.TED.tst2012.en-fr.fr.xml']\n",
    "    eng = []\n",
    "    fr = []\n",
    "\n",
    "    for i,j in zip(x_files, y_files):\n",
    "        tree_eng = ET.parse(i)\n",
    "        root_eng = tree_eng.getroot()\n",
    "\n",
    "        tree_fr = ET.parse(j)\n",
    "        root_fr = tree_fr.getroot()\n",
    "\n",
    "        for k in root_eng.iter('seg'):\n",
    "            eng.append(k.text.strip())\n",
    "\n",
    "        for l in root_fr.iter('seg'):\n",
    "            fr.append(l.text.strip())\n",
    "            \n",
    "    eng_norm = [normalizeString(l) for l in eng]\n",
    "    fr_norm = [normalizeString(l) for l in fr]\n",
    "    \n",
    "    pairs = zip(eng_norm, fr_norm)\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly_test(encoder, decoder, n=10):\n",
    "    actual_sen = []\n",
    "    pred_sen = []\n",
    "    for pair in pairs:\n",
    "        actual_sen.append(pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        pred_sen.append(output_sentence)\n",
    "        \n",
    "    return bleuScore(pred_sen, actual_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.42978064118128"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateRandomly_test(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Width = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> il est un ancien aborigenes australiens et c est aussi un artiste .\n",
      "= he s an australian aboriginal elder and he s also an artist .\n",
      "< SOS he s an australian aboriginal elder and he s also an artist . EOS\n",
      "\n",
      "> je suis acteur .\n",
      "= i m a performer .\n",
      "< SOS i m a performer . EOS\n",
      "\n",
      "> je suis optimiste .\n",
      "= i m optimistic .\n",
      "< SOS i m optimistic . EOS\n",
      "\n",
      "> je suis sous l eau dans la rivere avec ces poissons .\n",
      "= i m under the river with those fish .\n",
      "< SOS i m under the river with those fish . EOS\n",
      "\n",
      "> ils acceptent plus la tristesse que les gens plus jeunes .\n",
      "= they re more accepting of sadness than younger people are .\n",
      "< SOS they re more accepting of sadness than younger people are . EOS\n",
      "\n",
      "> je suis un artiste contemporain et je viens d un contexte inattendu .\n",
      "= i m a contemporary artist with a bit of an unexpected background .\n",
      "< SOS i m a contemporary artist with a bit of an unexpected background . EOS\n",
      "\n",
      "> ils sont aussi assez riches et aises et toutes ces autres sortes de choses .\n",
      "= they re also fairly wealthy and affluent and all these other sorts of things .\n",
      "< SOS they re also fairly wealthy and affluent and all these other sorts of things . EOS\n",
      "\n",
      "> nous nous habituons a une nouvelle facon d etre seuls ensemble .\n",
      "= we re getting used to a new way of being alone together .\n",
      "< SOS we re getting used to a new way of being alone together . EOS\n",
      "\n",
      "> je suis ingenieur procede .\n",
      "= i m a process engineer .\n",
      "< SOS i m a process engineer . EOS\n",
      "\n",
      "> je vais faire un peu de chirurgie .\n",
      "= i m going to do some surgery here .\n",
      "< SOS i m going to do some surgery here . EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.42978064118128"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateRandomly_test(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Width = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je vais decouper .\n",
      "= i m going to do some cuts .\n",
      "< SOS i m going to do some cuts . EOS\n",
      "\n",
      "> j en suis a sept ans et demi .\n",
      "= i m at seven and a half years .\n",
      "< SOS i m at seven and a half years . EOS\n",
      "\n",
      "> nous poussons l efficience du carburant vers de nouveaux sommets .\n",
      "= we re pushing fuel efficiency to new heights .\n",
      "< SOS we re pushing fuel efficiency to new heights . EOS\n",
      "\n",
      "> il est un ancien aborigenes australiens et c est aussi un artiste .\n",
      "= he s an australian aboriginal elder and he s also an artist .\n",
      "< SOS he s an australian aboriginal elder and he s also an artist . EOS\n",
      "\n",
      "> il s interesse a la facon dont nous voyons comme un animal combien nous sommes interesses par le mimetisme et le camouflage .\n",
      "= he is interested in how we see as an animal how we are interested in mimicry and camouflage .\n",
      "< SOS he is interested in how we see as an animal how we are interested in mimicry and camouflage . EOS\n",
      "\n",
      "> j en suis un exemple extreme .\n",
      "= i m an extreme example of this .\n",
      "< SOS i m an extreme example of this . EOS\n",
      "\n",
      "> nous commencons a vendre des voitures electriques et c est genial .\n",
      "= we re starting to sell electric cars which is great .\n",
      "< SOS we re starting to sell electric cars which is great . EOS\n",
      "\n",
      "> nous allons construire des voitures intelligentes mais nous devons aussi construire des routes intelligentes des parkings intelligents des systemes de transport public intelligents etc .\n",
      "= we are going to build smart cars but we also need to build smart roads smart parking smart public transportation systems and more .\n",
      "< SOS we are going to build smart cars but we also need to build smart roads smart parking smart public transportation systems and more . EOS\n",
      "\n",
      "> je vais decouper .\n",
      "= i m going to do some cuts .\n",
      "< SOS i m going to do some cuts . EOS\n",
      "\n",
      "> je suis une femme qui aime recevoir des textos qui va vous dire que trop de textos peuvent etre un probleme .\n",
      "= i m a woman who loves getting texts who s going to tell you that too many of them can be a problem .\n",
      "< SOS i m a woman who loves getting texts who s going to tell you that too many of them can be a problem . EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.42978064118128"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateRandomly_test(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact on results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = nous sommes optimiste par la chirurgie .\n",
      "output = SOS we re smitten with technology . EOS\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"nous sommes optimiste par la chirurgie .\") #beam width = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = nous sommes optimiste par la chirurgie .\n",
      "output = SOS we re smitten with technology . EOS\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"nous sommes optimiste par la chirurgie .\") #beam width = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = nous sommes optimiste par la chirurgie .\n",
      "output = SOS we re smitten with technology . EOS\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"nous sommes optimiste par la chirurgie .\") #beam width = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = nous sommes optimiste par la chirurgie .\n",
      "output = SOS we re smitten with technology . EOS\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"nous sommes optimiste par la chirurgie .\") #beam width = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Width = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> nous developpons des transmissions alternatives qui vont rendre les voitures abordables dans tous les sens du terme economiquement socialement et ecologiquement .\n",
      "= we re developing alternative power trains that are going to make cars affordable in every sense of the word economically socially and environmentally .\n",
      "< SOS we re developing alternative power trains that are going to make cars affordable in every sense of the word economically socially and environmentally . EOS\n",
      "\n",
      "> je ne suis pas sur que les chimpanzes l aient lu mais c est sur qu ils paraissaient interesses .\n",
      "= i m not sure how well the chimpanzees read it but they surely seemed interested in the book .\n",
      "< SOS i m not sure how well the chimpanzees read it but they surely seemed interested in the book . EOS\n",
      "\n",
      "> je vais l organiser et la diriger et l ouvrir au monde .\n",
      "= i m going to organize it and direct it and get it going in the world .\n",
      "< SOS i m going to organize it and direct it and get it going in the world . EOS\n",
      "\n",
      "> je suis un savant autiste ou plus exactement un autiste savant avec un fonctionnement eleve .\n",
      "= i m a savant or more precisely a high functioning autistic savant .\n",
      "< SOS i m a savant or more precisely a high functioning autistic savant . EOS\n",
      "\n",
      "> je vais decouper .\n",
      "= i m going to do some cuts .\n",
      "< SOS i m going to do some cuts . EOS\n",
      "\n",
      "> je vais decouper des veines des arteres oups ! . . .\n",
      "= i m going to cut some veins arteries . oops ! . . .\n",
      "< SOS i m going to cut some veins arteries . oops ! . . . EOS\n",
      "\n",
      "> nous allons construire des voitures intelligentes mais nous devons aussi construire des routes intelligentes des parkings intelligents des systemes de transport public intelligents etc .\n",
      "= we are going to build smart cars but we also need to build smart roads smart parking smart public transportation systems and more .\n",
      "< SOS we are going to build smart cars but we also need to build smart roads smart parking smart public transportation systems and more . EOS\n",
      "\n",
      "> je suis un artiste contemporain et je viens d un contexte inattendu .\n",
      "= i m a contemporary artist with a bit of an unexpected background .\n",
      "< SOS i m a contemporary artist with a bit of an unexpected background . EOS\n",
      "\n",
      "> ils s entrainent juste .\n",
      "= they re just practicing .\n",
      "< SOS they re just practicing . EOS\n",
      "\n",
      "> nous nous habituons a une nouvelle facon d etre seuls ensemble .\n",
      "= we re getting used to a new way of being alone together .\n",
      "< SOS we re getting used to a new way of being alone together . EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.42978064118128"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateRandomly_test(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length Penalty application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> nous sommes seuls mais nous avons peur de l intimite .\n",
      "= we re lonely but we re afraid of intimacy .\n",
      "< SOS we re lonely but we re afraid of intimacy . EOS\n",
      "\n",
      "> je suis optimiste .\n",
      "= i m optimistic .\n",
      "< SOS i m optimistic . EOS\n",
      "\n",
      "> ils sont plus heureux que les gens d age moyen et certainement que les jeunes .\n",
      "= they re happier than middle aged people and younger people certainly .\n",
      "< SOS they re happier than middle aged people and younger people certainly . EOS\n",
      "\n",
      "> je suis dans une ecole de commerce c est ce que nous faisons .\n",
      "= i m at a business school so that s what we do .\n",
      "< SOS i m at a business school so that s what we do . EOS\n",
      "\n",
      "> je ne suis pas sur que les chimpanzes l aient lu mais c est sur qu ils paraissaient interesses .\n",
      "= i m not sure how well the chimpanzees read it but they surely seemed interested in the book .\n",
      "< SOS i m not sure how well the chimpanzees read it but they surely seemed interested in the book . EOS\n",
      "\n",
      "> nous allons construire des voitures intelligentes mais nous devons aussi construire des routes intelligentes des parkings intelligents des systemes de transport public intelligents etc .\n",
      "= we are going to build smart cars but we also need to build smart roads smart parking smart public transportation systems and more .\n",
      "< SOS we are going to build smart cars but we also need to build smart roads smart parking smart public transportation systems and more . EOS\n",
      "\n",
      "> je vais vous raconter comment j ai failli mourir il y a ans quand j ai decouvert que j etais en fait deja presque mort .\n",
      "= i m going to be sharing with you how four years ago i almost died found out i was in fact already almost dead .\n",
      "< SOS i m going to be sharing with you how four years ago i almost died found out i was in fact already almost dead . EOS\n",
      "\n",
      "> je suis dans une ecole de commerce c est ce que nous faisons .\n",
      "= i m at a business school so that s what we do .\n",
      "< SOS i m at a business school so that s what we do . EOS\n",
      "\n",
      "> je vais vous montrer .\n",
      "= i m going to do some demonstrations .\n",
      "< SOS i m going to do some demonstrations . EOS\n",
      "\n",
      "> je vais decouper des veines des arteres oups ! . . .\n",
      "= i m going to cut some veins arteries . oops ! . . .\n",
      "< SOS i m going to cut some veins arteries . oops ! . . . EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.42978064118128"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateRandomly_test(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
